{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "This practice relies on training the model using the [Universal Dependencies 2.4](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2988#) corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-treebanks-v2.4.tgz --> ud-treebanks-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-treebanks-v2.4.tgz\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 16  326M   16 52.8M    0     0   682k      0  0:08:10  0:01:19  0:06:51  858k\n",
      "curl: (18) transfer closed with 287118753 bytes remaining to read\n",
      "\n",
      "[2/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-documentation-v2.4.tgz --> ud-documentation-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-documentation-v2.4.tgz\n",
      " 71 73.7M   71 52.8M    0     0   678k      0  0:01:51  0:01:19  0:00:32  664k02:43  0:00:10  0:02:33  588k    0  0:01:58  0:00:46  0:01:12  411k\n",
      "curl: (18) transfer closed with 21936762 bytes remaining to read\n",
      "\n",
      "[3/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-tools-v2.4.tgz --> ud-tools-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-tools-v2.4.tgz\n",
      "100  270k  100  270k    0     0   132k      0  0:00:02  0:00:02 --:--:--  153k\n"
     ]
    }
   ],
   "source": [
    "!curl --remote-name-all https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988{/ud-treebanks-v2.4.tgz,/ud-documentation-v2.4.tgz,/ud-tools-v2.4.tgz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "gzip: stdin: unexpected end of file\r\n",
      "tar: Unexpected EOF in archive\r\n",
      "tar: Unexpected EOF in archive\r\n",
      "tar: Error is not recoverable: exiting now\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xf ud-treebanks-v2.4.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `count`, `countB`, and `p`, respectively functions to count how many times a tag is in the corpus, how many times a tag is in the corpus given another previous one, and finally, the probability of a tag given another previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tag, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    for token in sentence:\n",
    "      if token.upos == tag:\n",
    "        count+=1\n",
    "  return count\n",
    "\n",
    "def countB(tagi, tagi_1, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    idx = 1\n",
    "    while idx <= len(sentence):\n",
    "      if sentence[idx-1].upos == tagi and sentence[idx-2].upos == tagi_1:\n",
    "        count+=1    \n",
    "      idx+=1\n",
    "  return count\n",
    "\n",
    "def p(tagi, tagi_1, corpus):\n",
    "  num = countB(tagi_1, tagi, corpus)\n",
    "  den = count(tagi, corpus)\n",
    "  return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define the training corpus and discover the tags inside it. \n",
    "\n",
    "Let's also build the transition matrix `tm` that gets the probability of change between tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some PRON\n",
      "of ADP\n",
      "the DET\n",
      "content NOUN\n",
      "in ADP\n",
      "this DET\n",
      "topic NOUN\n",
      "may AUX\n",
      "not PART\n",
      "be AUX\n",
      "applicable ADJ\n",
      "to ADP\n",
      "some DET\n",
      "language NOUN\n",
      ". PUNCT\n",
      "0\n",
      "Transition Matrix\n",
      "-----------------\n",
      "       PUNCT  ADJ  ADP  AUX  DET  PART  NOUN  PRON\n",
      "ADJ      0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "ADP      1.0  1.0  1.0  1.0  1.0   1.0   1.0   1.0\n",
      "AUX      0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "DET      0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "NOUN     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "PART     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "PRON     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n",
      "PUNCT    0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "import pyconll\n",
    "import pyconll.util\n",
    "import pandas\n",
    "\n",
    "UD_ENGLISH_TRAIN = './ud-treebanks-v2.4/UD_English-LinES/en_lines-ud-train.conllu'\n",
    "\n",
    "train = pyconll.load_from_file(UD_ENGLISH_TRAIN)\n",
    "train = [train[2]]\n",
    "\n",
    "tags = set()\n",
    "\n",
    "for sentence in train:\n",
    "  for token in sentence:\n",
    "    print(token.lemma, token.upos)\n",
    "    tags.add(token.upos)\n",
    "    \n",
    "print(countB('NOUN', 'DET', train))\n",
    "    \n",
    "tags = {tag: 0 for tag in tags}\n",
    "tm = {tag: tags for tag in tags}\n",
    "\n",
    "for rowtag in tm:\n",
    "  for coltag in tm[rowtag]:\n",
    "    tm[rowtag][coltag] = p(rowtag, coltag, train)\n",
    "\n",
    "print('Transition Matrix')\n",
    "print('-----------------')\n",
    "print(pandas.DataFrame(tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.999999999999996\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "for x in tm:\n",
    "    for y in tm[x]:\n",
    "        summ += tm[x][y]\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define two functions `tag_word_count` to tell how many times a word with a specific tag appears in the corpus, and `p_B` to define the probability of having such word with such tag in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_word_count(tag, word, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    for token in sentence:\n",
    "      if word == token.lemma and token.upos == tag:\n",
    "        count += 1\n",
    "  return count\n",
    "\n",
    "def p_B(tag, word, corpus):\n",
    "  num = tag_word_count(tag, word, corpus)\n",
    "  den = count(tag, corpus)\n",
    "  return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the training functions, let's define `ctrl_phrase` as a testing phrase to check its B matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            you      will      back       the      bill\n",
      "ADJ    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "ADP    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "ADV    0.000000  0.000000  0.024531  0.000722  0.000000\n",
      "AUX    0.000000  0.052336  0.000000  0.000000  0.000000\n",
      "CCONJ  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "DET    0.000000  0.000000  0.000000  0.591573  0.000000\n",
      "INTJ   0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "NOUN   0.000000  0.000443  0.001993  0.000000  0.000111\n",
      "NUM    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "PART   0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "PRON   0.097779  0.000000  0.000000  0.000000  0.000000\n",
      "PROPN  0.000000  0.000000  0.000000  0.000000  0.000599\n",
      "PUNCT  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "SCONJ  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "SYM    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "VERB   0.000000  0.000169  0.000507  0.000000  0.000000\n",
      "X      0.000000  0.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "ctrl_phrase = 'you will back the bill'.split()\n",
    "\n",
    "mb = {word: {tag: 0 for tag in tags} for word in ctrl_phrase}\n",
    "\n",
    "for word in ctrl_phrase:\n",
    "  for sentence in train:\n",
    "    for token in sentence:\n",
    "      if token.lemma == word:\n",
    "        mb[word][token.upos] = p_B(token.upos, word, train)\n",
    "\n",
    "print(pandas.DataFrame(mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define a list of dictionaries `hmm` to save the Hidden Markov Model for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 0.09777870043595599, 'upos': 'PRON', 'word': 'you'}\n",
      "{'p': 0.052336448598130844, 'upos': 'AUX', 'word': 'will'}\n",
      "{'p': 0.024531024531024532, 'upos': 'ADV', 'word': 'back'}\n",
      "{'p': 0.591572799332499, 'upos': 'DET', 'word': 'the'}\n",
      "{'p': 0.0005991611743559018, 'upos': 'PROPN', 'word': 'bill'}\n"
     ]
    }
   ],
   "source": [
    "hmm = []\n",
    "for word in mb:\n",
    "  argmax = {'p': 0, 'upos': '', 'word': word}\n",
    "  for tag in mb[word]:\n",
    "    if mb[word][tag] > argmax['p']:\n",
    "      argmax = {'p': mb[word][tag], 'upos': tag, 'word': word}\n",
    "  hmm.append(argmax)\n",
    "\n",
    "for e in hmm:\n",
    "  print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
