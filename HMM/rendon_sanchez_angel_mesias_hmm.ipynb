{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "This practice relies on training the model using the [Universal Dependencies 2.4](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2988#) corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-treebanks-v2.4.tgz --> ud-treebanks-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-treebanks-v2.4.tgz\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  326M  100  326M    0     0   596k      0  0:09:21  0:09:21 --:--:-- 1134k  0     0   810k      0  0:06:52  0:01:08  0:05:44  459k    0  0:07:18  0:01:16  0:06:02  344k02k      0  0:07:55  0:01:41  0:06:14  483k    0   601k      0  0:09:16  0:03:49  0:05:27  495k0     0   592k      0  0:09:24  0:05:23  0:04:01  624k   613k      0  0:09:05  0:07:11  0:01:54  579k    0   589k      0  0:09:27  0:09:07  0:00:20  210k\n",
      "\n",
      "[2/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-documentation-v2.4.tgz --> ud-documentation-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-documentation-v2.4.tgz\n",
      " 82 73.7M   82 60.5M    0     0   685k      0  0:01:50  0:01:30  0:00:20  946k  0  0:01:51  0:01:26  0:00:25  982k\n",
      "curl: (18) transfer closed with 13825474 bytes remaining to read\n",
      "\n",
      "[3/3]: https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-tools-v2.4.tgz --> ud-tools-v2.4.tgz\n",
      "--_curl_--https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988/ud-tools-v2.4.tgz\n",
      "100  270k  100  270k    0     0   161k      0  0:00:01  0:00:01 --:--:--  296k\n"
     ]
    }
   ],
   "source": [
    "!curl --remote-name-all https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-2988{/ud-treebanks-v2.4.tgz,/ud-documentation-v2.4.tgz,/ud-tools-v2.4.tgz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf ud-treebanks-v2.4.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `count`, `countB`, and `p`, respectively functions to count how many times a tag is in the corpus, how many times a tag is in the corpus given another previous one, and finally, the probability of a tag given another previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tag, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    for token in sentence:\n",
    "      if token.upos == tag:\n",
    "        count+=1\n",
    "  return count\n",
    "\n",
    "def countB(tagi, tagi_1, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    idx = 1\n",
    "    while idx <= len(sentence):\n",
    "      if sentence[idx-1].upos == tagi and sentence[idx-2].upos == tagi_1:\n",
    "        count+=1    \n",
    "      idx+=1\n",
    "  return count\n",
    "\n",
    "def p(tagi, tagi_1, corpus):\n",
    "  num = countB(tagi_1, tagi, corpus)\n",
    "  den = count(tagi, corpus)\n",
    "  return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define the training corpus and discover the tags inside it. \n",
    "\n",
    "Let's also build the transition matrix `tm` that gets the probability of change between tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix\n",
      "-----------------\n",
      "           PRON      INTJ       AUX       ADV         X       ADP     PUNCT  \\\n",
      "ADJ    0.008415  0.008415  0.008415  0.008415  0.008415  0.008415  0.008415   \n",
      "ADP    0.235496  0.235496  0.235496  0.235496  0.235496  0.235496  0.235496   \n",
      "ADV    0.026572  0.026572  0.026572  0.026572  0.026572  0.026572  0.026572   \n",
      "AUX    0.064548  0.064548  0.064548  0.064548  0.064548  0.064548  0.064548   \n",
      "CCONJ  0.054584  0.054584  0.054584  0.054584  0.054584  0.054584  0.054584   \n",
      "DET    0.007418  0.007418  0.007418  0.007418  0.007418  0.007418  0.007418   \n",
      "INTJ   0.000111  0.000111  0.000111  0.000111  0.000111  0.000111  0.000111   \n",
      "NOUN   0.103521  0.103521  0.103521  0.103521  0.103521  0.103521  0.103521   \n",
      "NUM    0.004539  0.004539  0.004539  0.004539  0.004539  0.004539  0.004539   \n",
      "PART   0.022697  0.022697  0.022697  0.022697  0.022697  0.022697  0.022697   \n",
      "PRON   0.037201  0.037201  0.037201  0.037201  0.037201  0.037201  0.037201   \n",
      "PROPN  0.016275  0.016275  0.016275  0.016275  0.016275  0.016275  0.016275   \n",
      "PUNCT  0.325066  0.325066  0.325066  0.325066  0.325066  0.325066  0.325066   \n",
      "SCONJ  0.013508  0.013508  0.013508  0.013508  0.013508  0.013508  0.013508   \n",
      "SYM    0.000111  0.000111  0.000111  0.000111  0.000111  0.000111  0.000111   \n",
      "VERB   0.079938  0.079938  0.079938  0.079938  0.079938  0.079938  0.079938   \n",
      "X      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            NUM       ADJ       SYM     PROPN     CCONJ     SCONJ      VERB  \\\n",
      "ADJ    0.008415  0.008415  0.008415  0.008415  0.008415  0.008415  0.008415   \n",
      "ADP    0.235496  0.235496  0.235496  0.235496  0.235496  0.235496  0.235496   \n",
      "ADV    0.026572  0.026572  0.026572  0.026572  0.026572  0.026572  0.026572   \n",
      "AUX    0.064548  0.064548  0.064548  0.064548  0.064548  0.064548  0.064548   \n",
      "CCONJ  0.054584  0.054584  0.054584  0.054584  0.054584  0.054584  0.054584   \n",
      "DET    0.007418  0.007418  0.007418  0.007418  0.007418  0.007418  0.007418   \n",
      "INTJ   0.000111  0.000111  0.000111  0.000111  0.000111  0.000111  0.000111   \n",
      "NOUN   0.103521  0.103521  0.103521  0.103521  0.103521  0.103521  0.103521   \n",
      "NUM    0.004539  0.004539  0.004539  0.004539  0.004539  0.004539  0.004539   \n",
      "PART   0.022697  0.022697  0.022697  0.022697  0.022697  0.022697  0.022697   \n",
      "PRON   0.037201  0.037201  0.037201  0.037201  0.037201  0.037201  0.037201   \n",
      "PROPN  0.016275  0.016275  0.016275  0.016275  0.016275  0.016275  0.016275   \n",
      "PUNCT  0.325066  0.325066  0.325066  0.325066  0.325066  0.325066  0.325066   \n",
      "SCONJ  0.013508  0.013508  0.013508  0.013508  0.013508  0.013508  0.013508   \n",
      "SYM    0.000111  0.000111  0.000111  0.000111  0.000111  0.000111  0.000111   \n",
      "VERB   0.079938  0.079938  0.079938  0.079938  0.079938  0.079938  0.079938   \n",
      "X      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            DET      PART      NOUN  \n",
      "ADJ    0.008415  0.008415  0.008415  \n",
      "ADP    0.235496  0.235496  0.235496  \n",
      "ADV    0.026572  0.026572  0.026572  \n",
      "AUX    0.064548  0.064548  0.064548  \n",
      "CCONJ  0.054584  0.054584  0.054584  \n",
      "DET    0.007418  0.007418  0.007418  \n",
      "INTJ   0.000111  0.000111  0.000111  \n",
      "NOUN   0.103521  0.103521  0.103521  \n",
      "NUM    0.004539  0.004539  0.004539  \n",
      "PART   0.022697  0.022697  0.022697  \n",
      "PRON   0.037201  0.037201  0.037201  \n",
      "PROPN  0.016275  0.016275  0.016275  \n",
      "PUNCT  0.325066  0.325066  0.325066  \n",
      "SCONJ  0.013508  0.013508  0.013508  \n",
      "SYM    0.000111  0.000111  0.000111  \n",
      "VERB   0.079938  0.079938  0.079938  \n",
      "X      0.000000  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pyconll\n",
    "import pyconll.util\n",
    "import pandas\n",
    "\n",
    "UD_ENGLISH_TRAIN = './ud-treebanks-v2.4/UD_English-LinES/en_lines-ud-train.conllu'\n",
    "\n",
    "train = pyconll.load_from_file(UD_ENGLISH_TRAIN)\n",
    "\n",
    "tags = set()\n",
    "\n",
    "for sentence in train:\n",
    "  for token in sentence:\n",
    "    tags.add(token.upos)\n",
    "\n",
    "tags = {tag: 0 for tag in tags}\n",
    "tm = {tag: tags for tag in tags}\n",
    "\n",
    "for rowtag in tm:\n",
    "  for coltag in tm[rowtag]:\n",
    "    tm[rowtag][coltag] = p(rowtag, coltag, train)\n",
    "\n",
    "print('Transition Matrix')\n",
    "print('-----------------')\n",
    "print(pandas.DataFrame(tm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define two functions `tag_word_count` to tell how many times a word with a specific tag appears in the corpus, and `p_B` to define the probability of having such word with such tag in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_word_count(tag, word, corpus):\n",
    "  count = 0\n",
    "  for sentence in corpus:\n",
    "    for token in sentence:\n",
    "      if word == token.lemma and token.upos == tag:\n",
    "        count += 1\n",
    "  return count\n",
    "\n",
    "def p_B(tag, word, corpus):\n",
    "  num = tag_word_count(tag, word, corpus)\n",
    "  den = count(tag, corpus)\n",
    "  return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the training functions, let's define `ctrl_phrase` as a testing phrase to check its B matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            you      will      back       the      bill\n",
      "ADJ    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "ADP    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "ADV    0.000000  0.000000  0.024531  0.000722  0.000000\n",
      "AUX    0.000000  0.052336  0.000000  0.000000  0.000000\n",
      "CCONJ  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "DET    0.000000  0.000000  0.000000  0.591573  0.000000\n",
      "INTJ   0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "NOUN   0.000000  0.000443  0.001993  0.000000  0.000111\n",
      "NUM    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "PART   0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "PRON   0.097779  0.000000  0.000000  0.000000  0.000000\n",
      "PROPN  0.000000  0.000000  0.000000  0.000000  0.000599\n",
      "PUNCT  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "SCONJ  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "SYM    0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "VERB   0.000000  0.000169  0.000507  0.000000  0.000000\n",
      "X      0.000000  0.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "ctrl_phrase = 'you will back the bill'.split()\n",
    "\n",
    "mb = {word: {tag: 0 for tag in tags} for word in ctrl_phrase}\n",
    "\n",
    "for word in ctrl_phrase:\n",
    "  for sentence in train:\n",
    "    for token in sentence:\n",
    "      if token.lemma == word:\n",
    "        mb[word][token.upos] = p_B(token.upos, word, train)\n",
    "\n",
    "print(pandas.DataFrame(mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define a list of dictionaries `hmm` to save the Hidden Markov Model for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 0.09777870043595599, 'upos': 'PRON', 'word': 'you'}\n",
      "{'p': 0.052336448598130844, 'upos': 'AUX', 'word': 'will'}\n",
      "{'p': 0.024531024531024532, 'upos': 'ADV', 'word': 'back'}\n",
      "{'p': 0.591572799332499, 'upos': 'DET', 'word': 'the'}\n",
      "{'p': 0.0005991611743559018, 'upos': 'PROPN', 'word': 'bill'}\n"
     ]
    }
   ],
   "source": [
    "hmm = []\n",
    "for word in mb:\n",
    "  argmax = {'p': 0, 'upos': '', 'word': word}\n",
    "  for tag in mb[word]:\n",
    "    if mb[word][tag] > argmax['p']:\n",
    "      argmax = {'p': mb[word][tag], 'upos': tag, 'word': word}\n",
    "  hmm.append(argmax)\n",
    "\n",
    "for e in hmm:\n",
    "  print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
