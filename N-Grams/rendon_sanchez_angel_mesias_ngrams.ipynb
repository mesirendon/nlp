{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Realizar un programa para computar unigramas, bigramas y trigramas. Los parámetros son: corpus y N (tamaño del \"gram\") y debe generar el modelo de lenguaje basado en el conteo de los n-grams. La salida puede ser un diccionario con la siguiente estructura:\n",
    "\n",
    "```\n",
    " Si N=2\n",
    "     { (A,F) : 0.2,\n",
    "       (D,F) : 0.15,\n",
    "       (B,G) : 0.3,\n",
    "       (B,H) : 0.1,\n",
    "     }\n",
    "```\n",
    "En este caso para el bigrama `(A,F)` la `P(F|A) = 0.2` y para el bigrama `(D,F)` la `P(F|D) = 0.15` y así para todos los bigramas. No incluir en el diccionario de salida las `P(X|Y)=0` (podrían ser muchas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "import re\n",
    "import collections\n",
    "import random\n",
    "import operator, functools\n",
    "import pandas\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "# Tuple flattening utility\n",
    "def flatten(t):\n",
    "    for element in t:\n",
    "        if isinstance(element, collections.Iterable) and not isinstance(element,str):\n",
    "            for x in flatten(element):\n",
    "                yield re.sub(r\"\\[\\d+\\]\",r\"\",x)\n",
    "        else:\n",
    "            yield re.sub(r\"\\[\\d+\\]\",r\"\",element)\n",
    "            \n",
    "def printer(corpus, result):\n",
    "    print('Corpus:')\n",
    "    for phrase in corpus:\n",
    "        print(phrase)\n",
    "    print('\\nTokens count:')\n",
    "    for token in result['tokens']:\n",
    "        print(token, ':', result['tokens'][token])\n",
    "\n",
    "    print('\\nGrams')\n",
    "    for gram in result['grams']:\n",
    "        print(gram, ':', result['grams'][gram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram generator\n",
    "def grams(corpus, gram):\n",
    "    individual_count = {}\n",
    "    gram_count = {}\n",
    "    grams_probs = {}\n",
    "    for phrase in corpus:\n",
    "        for token in phrase:\n",
    "            if token in individual_count:\n",
    "                individual_count[token] += 1\n",
    "            else:\n",
    "                individual_count[token] = 1\n",
    "        lists = []\n",
    "        for i in range(0, gram):\n",
    "            lists.append(phrase[i:])\n",
    "        tuples = lists.pop(0)\n",
    "        for item in lists:\n",
    "            tuples = list(zip(tuples, item))\n",
    "        if gram == 1:\n",
    "            tuples = list(map(lambda x: tuple([x]), tuples))\n",
    "        for item in tuples:\n",
    "            ngram = tuple(flatten(list(item)))\n",
    "            if ngram in gram_count:\n",
    "                gram_count[ngram]['count'] += 1\n",
    "            else:\n",
    "                gram_count[ngram] = {}\n",
    "                gram_count[ngram]['count'] = 1\n",
    "                gram_count[ngram]['probability'] = 0\n",
    "                \n",
    "    total_individual_tokens = sum(value for key, value in individual_count.items())\n",
    "    \n",
    "    for tupl in gram_count:\n",
    "        if gram == 1:\n",
    "            gram_count[tupl]['probability'] = gram_count[tupl]['count'] / total_individual_tokens\n",
    "        else:\n",
    "            gram_count[tupl]['probability'] = gram_count[tupl]['count'] / individual_count[tupl[0]]\n",
    "    \n",
    "    return {'grams': gram_count, 'tokens': individual_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = list(filter(lambda x: len(x) > 0, text.splitlines()))\n",
    "\n",
    "    for idx, line in enumerate(text):\n",
    "        text[idx] = WordPunctTokenizer().tokenize(line)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Construir el modelo probabilístico de unigramas y bigramas para:\n",
    "\n",
    "```\n",
    "corpus = [['A', 'B', 'C', 'D', 'E'],\n",
    "          ['D', 'E', 'C', 'D', 'E'],\n",
    "          ['A', 'C', 'D', 'D']\n",
    "         ]\n",
    "```\n",
    "En este formato el corpus tiene tres frases y los términos o \"tokens\" están separados por comas (editar al formato que estén usando en su programa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    ['A', 'B', 'C', 'D', 'E'],\n",
    "    ['D', 'E', 'C', 'D', 'E'],\n",
    "    ['A', 'C', 'D', 'D']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['D', 'E', 'C', 'D', 'E']\n",
      "['A', 'C', 'D', 'D']\n",
      "\n",
      "Tokens count:\n",
      "A : 2\n",
      "B : 1\n",
      "C : 3\n",
      "D : 5\n",
      "E : 3\n",
      "\n",
      "Grams\n",
      "('A',) : {'count': 2, 'probability': 0.14285714285714285}\n",
      "('B',) : {'count': 1, 'probability': 0.07142857142857142}\n",
      "('C',) : {'count': 3, 'probability': 0.21428571428571427}\n",
      "('D',) : {'count': 5, 'probability': 0.35714285714285715}\n",
      "('E',) : {'count': 3, 'probability': 0.21428571428571427}\n"
     ]
    }
   ],
   "source": [
    "printer(corpus, grams(corpus, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['D', 'E', 'C', 'D', 'E']\n",
      "['A', 'C', 'D', 'D']\n",
      "\n",
      "Tokens count:\n",
      "A : 2\n",
      "B : 1\n",
      "C : 3\n",
      "D : 5\n",
      "E : 3\n",
      "\n",
      "Grams\n",
      "('A', 'B') : {'count': 1, 'probability': 0.5}\n",
      "('B', 'C') : {'count': 1, 'probability': 1.0}\n",
      "('C', 'D') : {'count': 3, 'probability': 1.0}\n",
      "('D', 'E') : {'count': 3, 'probability': 0.6}\n",
      "('E', 'C') : {'count': 1, 'probability': 0.3333333333333333}\n",
      "('A', 'C') : {'count': 1, 'probability': 0.5}\n",
      "('D', 'D') : {'count': 1, 'probability': 0.2}\n"
     ]
    }
   ],
   "source": [
    "printer(corpus, grams(corpus, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['D', 'E', 'C', 'D', 'E']\n",
      "['A', 'C', 'D', 'D']\n",
      "\n",
      "Tokens count:\n",
      "A : 2\n",
      "B : 1\n",
      "C : 3\n",
      "D : 5\n",
      "E : 3\n",
      "\n",
      "Grams\n",
      "('A', 'B', 'C') : {'count': 1, 'probability': 0.5}\n",
      "('B', 'C', 'D') : {'count': 1, 'probability': 1.0}\n",
      "('C', 'D', 'E') : {'count': 2, 'probability': 0.6666666666666666}\n",
      "('D', 'E', 'C') : {'count': 1, 'probability': 0.2}\n",
      "('E', 'C', 'D') : {'count': 1, 'probability': 0.3333333333333333}\n",
      "('A', 'C', 'D') : {'count': 1, 'probability': 0.5}\n",
      "('C', 'D', 'D') : {'count': 1, 'probability': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "printer(corpus, grams(corpus, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Construir un modelo probabilístico n-gram usando el programa, para dos documentos (pequeños) de su preferencia en el mismo idioma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts taken from https://vitalik.ca/general/2019/04/03/collusion.html\n",
    "text_A = '''However, that range of things that mechanisms of this type can do is limited. In the case of the content curation example above, we’re not really solving governance, we’re just scaling the functionality of a governance gadget that is already assumed to be trusted. One could try to replace the moderation panel with a prediction market on the price of a token representing the right to purchase advertising space, but in practice prices are too noisy an indicator to make this viable for anything but a very small number of very large decisions. And often the value that we’re trying to maximize is explicitly something other than maximum value of a coin.\n",
    "\n",
    "Let’s take a more explicit look at why, in the more general case where we can’t easily determine the value of a governance decision via its impact on the price of a token, good mechanisms for identifying public goods and bads unfortunately cannot be identity-free or collusion-safe. If one tries to preserve the property of a game being identity-free, building a system where identities don’t matter and only coins do, there is an impossible tradeoff between either failing to incentivize legitimate public goods or over-subsidizing plutocracy.'''\n",
    "\n",
    "text_B = '''The argument is as follows. Suppose that there is some author that is producing a public good (eg. a series of blog posts) that provides value to each member of a community of 10000 people. Suppose there exists some mechanism where members of the community can take an action that causes the author to receive a gain of $1. Unless the community members are extremely altruistic, for the mechanism to work the cost of taking this action must be much lower than $1, as otherwise the portion of the benefit captured by the member of the community supporting the author would be much smaller than the cost of supporting the author, and so the system collapses into a tragedy of the commons where no one supports the author. Hence, there must exist a way to cause the author to earn $1 at a cost much less than $1. But now suppose that there is also a fake community, which consists of 10000 fake sockpuppet accounts of the same wealthy attacker. This community takes all of the same actions as the real community, except instead of supporting the author, they support another fake account which is also a sockpuppet of the attacker. If it was possible for a member of the “real community” to give the author $1 at a personal cost of much less than $1, it’s possible for the attacker to give themselves $1 at a cost much less than $1 over and over again, and thereby drain the system’s funding. Any mechanism that can help genuinely under-coordinated parties coordinate will, without the right safeguards, also help already coordinated parties (such as many accounts controlled by the same person) over-coordinate, extracting money from the system.\n",
    "\n",
    "A similar challenge arises when the goal is not funding, but rather determining what content should be most visible. What content do you think would get more dollar value supporting it: a legitimately high quality blog article benefiting thousands of people but benefiting each individual person relatively slightly, or this?'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "['However', ',', 'that', 'range', 'of', 'things', 'that', 'mechanisms', 'of', 'this', 'type', 'can', 'do', 'is', 'limited', '.', 'In', 'the', 'case', 'of', 'the', 'content', 'curation', 'example', 'above', ',', 'we', '’', 're', 'not', 'really', 'solving', 'governance', ',', 'we', '’', 're', 'just', 'scaling', 'the', 'functionality', 'of', 'a', 'governance', 'gadget', 'that', 'is', 'already', 'assumed', 'to', 'be', 'trusted', '.', 'One', 'could', 'try', 'to', 'replace', 'the', 'moderation', 'panel', 'with', 'a', 'prediction', 'market', 'on', 'the', 'price', 'of', 'a', 'token', 'representing', 'the', 'right', 'to', 'purchase', 'advertising', 'space', ',', 'but', 'in', 'practice', 'prices', 'are', 'too', 'noisy', 'an', 'indicator', 'to', 'make', 'this', 'viable', 'for', 'anything', 'but', 'a', 'very', 'small', 'number', 'of', 'very', 'large', 'decisions', '.', 'And', 'often', 'the', 'value', 'that', 'we', '’', 're', 'trying', 'to', 'maximize', 'is', 'explicitly', 'something', 'other', 'than', 'maximum', 'value', 'of', 'a', 'coin', '.']\n",
      "['Let', '’', 's', 'take', 'a', 'more', 'explicit', 'look', 'at', 'why', ',', 'in', 'the', 'more', 'general', 'case', 'where', 'we', 'can', '’', 't', 'easily', 'determine', 'the', 'value', 'of', 'a', 'governance', 'decision', 'via', 'its', 'impact', 'on', 'the', 'price', 'of', 'a', 'token', ',', 'good', 'mechanisms', 'for', 'identifying', 'public', 'goods', 'and', 'bads', 'unfortunately', 'cannot', 'be', 'identity', '-', 'free', 'or', 'collusion', '-', 'safe', '.', 'If', 'one', 'tries', 'to', 'preserve', 'the', 'property', 'of', 'a', 'game', 'being', 'identity', '-', 'free', ',', 'building', 'a', 'system', 'where', 'identities', 'don', '’', 't', 'matter', 'and', 'only', 'coins', 'do', ',', 'there', 'is', 'an', 'impossible', 'tradeoff', 'between', 'either', 'failing', 'to', 'incentivize', 'legitimate', 'public', 'goods', 'or', 'over', '-', 'subsidizing', 'plutocracy', '.']\n",
      "\n",
      "Tokens count:\n",
      "However : 1\n",
      ", : 8\n",
      "that : 4\n",
      "range : 1\n",
      "of : 10\n",
      "things : 1\n",
      "mechanisms : 2\n",
      "this : 2\n",
      "type : 1\n",
      "can : 2\n",
      "do : 2\n",
      "is : 4\n",
      "limited : 1\n",
      ". : 6\n",
      "In : 1\n",
      "the : 11\n",
      "case : 2\n",
      "content : 1\n",
      "curation : 1\n",
      "example : 1\n",
      "above : 1\n",
      "we : 4\n",
      "’ : 6\n",
      "re : 3\n",
      "not : 1\n",
      "really : 1\n",
      "solving : 1\n",
      "governance : 3\n",
      "just : 1\n",
      "scaling : 1\n",
      "functionality : 1\n",
      "a : 10\n",
      "gadget : 1\n",
      "already : 1\n",
      "assumed : 1\n",
      "to : 7\n",
      "be : 2\n",
      "trusted : 1\n",
      "One : 1\n",
      "could : 1\n",
      "try : 1\n",
      "replace : 1\n",
      "moderation : 1\n",
      "panel : 1\n",
      "with : 1\n",
      "prediction : 1\n",
      "market : 1\n",
      "on : 2\n",
      "price : 2\n",
      "token : 2\n",
      "representing : 1\n",
      "right : 1\n",
      "purchase : 1\n",
      "advertising : 1\n",
      "space : 1\n",
      "but : 2\n",
      "in : 2\n",
      "practice : 1\n",
      "prices : 1\n",
      "are : 1\n",
      "too : 1\n",
      "noisy : 1\n",
      "an : 2\n",
      "indicator : 1\n",
      "make : 1\n",
      "viable : 1\n",
      "for : 2\n",
      "anything : 1\n",
      "very : 2\n",
      "small : 1\n",
      "number : 1\n",
      "large : 1\n",
      "decisions : 1\n",
      "And : 1\n",
      "often : 1\n",
      "value : 3\n",
      "trying : 1\n",
      "maximize : 1\n",
      "explicitly : 1\n",
      "something : 1\n",
      "other : 1\n",
      "than : 1\n",
      "maximum : 1\n",
      "coin : 1\n",
      "Let : 1\n",
      "s : 1\n",
      "take : 1\n",
      "more : 2\n",
      "explicit : 1\n",
      "look : 1\n",
      "at : 1\n",
      "why : 1\n",
      "general : 1\n",
      "where : 2\n",
      "t : 2\n",
      "easily : 1\n",
      "determine : 1\n",
      "decision : 1\n",
      "via : 1\n",
      "its : 1\n",
      "impact : 1\n",
      "good : 1\n",
      "identifying : 1\n",
      "public : 2\n",
      "goods : 2\n",
      "and : 2\n",
      "bads : 1\n",
      "unfortunately : 1\n",
      "cannot : 1\n",
      "identity : 2\n",
      "- : 4\n",
      "free : 2\n",
      "or : 2\n",
      "collusion : 1\n",
      "safe : 1\n",
      "If : 1\n",
      "one : 1\n",
      "tries : 1\n",
      "preserve : 1\n",
      "property : 1\n",
      "game : 1\n",
      "being : 1\n",
      "building : 1\n",
      "system : 1\n",
      "identities : 1\n",
      "don : 1\n",
      "matter : 1\n",
      "only : 1\n",
      "coins : 1\n",
      "there : 1\n",
      "impossible : 1\n",
      "tradeoff : 1\n",
      "between : 1\n",
      "either : 1\n",
      "failing : 1\n",
      "incentivize : 1\n",
      "legitimate : 1\n",
      "over : 1\n",
      "subsidizing : 1\n",
      "plutocracy : 1\n",
      "\n",
      "Grams\n",
      "('However',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "(',',) : {'count': 8, 'probability': 0.034482758620689655}\n",
      "('that',) : {'count': 4, 'probability': 0.017241379310344827}\n",
      "('range',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('of',) : {'count': 10, 'probability': 0.04310344827586207}\n",
      "('things',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('mechanisms',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('this',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('type',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('can',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('do',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('is',) : {'count': 4, 'probability': 0.017241379310344827}\n",
      "('limited',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('.',) : {'count': 6, 'probability': 0.02586206896551724}\n",
      "('In',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('the',) : {'count': 11, 'probability': 0.04741379310344827}\n",
      "('case',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('content',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('curation',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('example',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('above',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('we',) : {'count': 4, 'probability': 0.017241379310344827}\n",
      "('’',) : {'count': 6, 'probability': 0.02586206896551724}\n",
      "('re',) : {'count': 3, 'probability': 0.01293103448275862}\n",
      "('not',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('really',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('solving',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('governance',) : {'count': 3, 'probability': 0.01293103448275862}\n",
      "('just',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('scaling',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('functionality',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('a',) : {'count': 10, 'probability': 0.04310344827586207}\n",
      "('gadget',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('already',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('assumed',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('to',) : {'count': 7, 'probability': 0.03017241379310345}\n",
      "('be',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('trusted',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('One',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('could',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('try',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('replace',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('moderation',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('panel',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('with',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('prediction',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('market',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('on',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('price',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('token',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('representing',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('right',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('purchase',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('advertising',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('space',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('but',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('in',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('practice',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('prices',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('are',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('too',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('noisy',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('an',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('indicator',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('make',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('viable',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('for',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('anything',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('very',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('small',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('number',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('large',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('decisions',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('And',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('often',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('value',) : {'count': 3, 'probability': 0.01293103448275862}\n",
      "('trying',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('maximize',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('explicitly',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('something',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('other',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('than',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('maximum',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('coin',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('Let',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('s',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('take',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('more',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('explicit',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('look',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('at',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('why',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('general',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('where',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('t',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('easily',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('determine',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('decision',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('via',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('its',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('impact',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('good',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('identifying',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('public',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('goods',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('and',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('bads',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('unfortunately',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('cannot',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('identity',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('-',) : {'count': 4, 'probability': 0.017241379310344827}\n",
      "('free',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('or',) : {'count': 2, 'probability': 0.008620689655172414}\n",
      "('collusion',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('safe',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('If',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('one',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('tries',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('preserve',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('property',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('game',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('being',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('building',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('system',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('identities',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('don',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('matter',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('only',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('coins',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('there',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('impossible',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('tradeoff',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('between',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('either',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('failing',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('incentivize',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('legitimate',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('over',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('subsidizing',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "('plutocracy',) : {'count': 1, 'probability': 0.004310344827586207}\n",
      "\n",
      "\n",
      "Corpus:\n",
      "['The', 'argument', 'is', 'as', 'follows', '.', 'Suppose', 'that', 'there', 'is', 'some', 'author', 'that', 'is', 'producing', 'a', 'public', 'good', '(', 'eg', '.', 'a', 'series', 'of', 'blog', 'posts', ')', 'that', 'provides', 'value', 'to', 'each', 'member', 'of', 'a', 'community', 'of', '10000', 'people', '.', 'Suppose', 'there', 'exists', 'some', 'mechanism', 'where', 'members', 'of', 'the', 'community', 'can', 'take', 'an', 'action', 'that', 'causes', 'the', 'author', 'to', 'receive', 'a', 'gain', 'of', '$', '1', '.', 'Unless', 'the', 'community', 'members', 'are', 'extremely', 'altruistic', ',', 'for', 'the', 'mechanism', 'to', 'work', 'the', 'cost', 'of', 'taking', 'this', 'action', 'must', 'be', 'much', 'lower', 'than', '$', '1', ',', 'as', 'otherwise', 'the', 'portion', 'of', 'the', 'benefit', 'captured', 'by', 'the', 'member', 'of', 'the', 'community', 'supporting', 'the', 'author', 'would', 'be', 'much', 'smaller', 'than', 'the', 'cost', 'of', 'supporting', 'the', 'author', ',', 'and', 'so', 'the', 'system', 'collapses', 'into', 'a', 'tragedy', 'of', 'the', 'commons', 'where', 'no', 'one', 'supports', 'the', 'author', '.', 'Hence', ',', 'there', 'must', 'exist', 'a', 'way', 'to', 'cause', 'the', 'author', 'to', 'earn', '$', '1', 'at', 'a', 'cost', 'much', 'less', 'than', '$', '1', '.', 'But', 'now', 'suppose', 'that', 'there', 'is', 'also', 'a', 'fake', 'community', ',', 'which', 'consists', 'of', '10000', 'fake', 'sockpuppet', 'accounts', 'of', 'the', 'same', 'wealthy', 'attacker', '.', 'This', 'community', 'takes', 'all', 'of', 'the', 'same', 'actions', 'as', 'the', 'real', 'community', ',', 'except', 'instead', 'of', 'supporting', 'the', 'author', ',', 'they', 'support', 'another', 'fake', 'account', 'which', 'is', 'also', 'a', 'sockpuppet', 'of', 'the', 'attacker', '.', 'If', 'it', 'was', 'possible', 'for', 'a', 'member', 'of', 'the', '“', 'real', 'community', '”', 'to', 'give', 'the', 'author', '$', '1', 'at', 'a', 'personal', 'cost', 'of', 'much', 'less', 'than', '$', '1', ',', 'it', '’', 's', 'possible', 'for', 'the', 'attacker', 'to', 'give', 'themselves', '$', '1', 'at', 'a', 'cost', 'much', 'less', 'than', '$', '1', 'over', 'and', 'over', 'again', ',', 'and', 'thereby', 'drain', 'the', 'system', '’', 's', 'funding', '.', 'Any', 'mechanism', 'that', 'can', 'help', 'genuinely', 'under', '-', 'coordinated', 'parties', 'coordinate', 'will', ',', 'without', 'the', 'right', 'safeguards', ',', 'also', 'help', 'already', 'coordinated', 'parties', '(', 'such', 'as', 'many', 'accounts', 'controlled', 'by', 'the', 'same', 'person', ')', 'over', '-', 'coordinate', ',', 'extracting', 'money', 'from', 'the', 'system', '.']\n",
      "['A', 'similar', 'challenge', 'arises', 'when', 'the', 'goal', 'is', 'not', 'funding', ',', 'but', 'rather', 'determining', 'what', 'content', 'should', 'be', 'most', 'visible', '.', 'What', 'content', 'do', 'you', 'think', 'would', 'get', 'more', 'dollar', 'value', 'supporting', 'it', ':', 'a', 'legitimately', 'high', 'quality', 'blog', 'article', 'benefiting', 'thousands', 'of', 'people', 'but', 'benefiting', 'each', 'individual', 'person', 'relatively', 'slightly', ',', 'or', 'this', '?']\n",
      "\n",
      "Tokens count:\n",
      "The : 1\n",
      "argument : 1\n",
      "is : 6\n",
      "as : 4\n",
      "follows : 1\n",
      ". : 11\n",
      "Suppose : 2\n",
      "that : 6\n",
      "there : 4\n",
      "some : 2\n",
      "author : 8\n",
      "producing : 1\n",
      "a : 13\n",
      "public : 1\n",
      "good : 1\n",
      "( : 2\n",
      "eg : 1\n",
      "series : 1\n",
      "of : 18\n",
      "blog : 2\n",
      "posts : 1\n",
      ") : 2\n",
      "provides : 1\n",
      "value : 2\n",
      "to : 7\n",
      "each : 2\n",
      "member : 3\n",
      "community : 8\n",
      "10000 : 2\n",
      "people : 2\n",
      "exists : 1\n",
      "mechanism : 3\n",
      "where : 2\n",
      "members : 2\n",
      "the : 29\n",
      "can : 2\n",
      "take : 1\n",
      "an : 1\n",
      "action : 2\n",
      "causes : 1\n",
      "receive : 1\n",
      "gain : 1\n",
      "$ : 8\n",
      "1 : 8\n",
      "Unless : 1\n",
      "are : 1\n",
      "extremely : 1\n",
      "altruistic : 1\n",
      ", : 14\n",
      "for : 3\n",
      "work : 1\n",
      "cost : 5\n",
      "taking : 1\n",
      "this : 2\n",
      "must : 2\n",
      "be : 3\n",
      "much : 5\n",
      "lower : 1\n",
      "than : 5\n",
      "otherwise : 1\n",
      "portion : 1\n",
      "benefit : 1\n",
      "captured : 1\n",
      "by : 2\n",
      "supporting : 4\n",
      "would : 2\n",
      "smaller : 1\n",
      "and : 3\n",
      "so : 1\n",
      "system : 3\n",
      "collapses : 1\n",
      "into : 1\n",
      "tragedy : 1\n",
      "commons : 1\n",
      "no : 1\n",
      "one : 1\n",
      "supports : 1\n",
      "Hence : 1\n",
      "exist : 1\n",
      "way : 1\n",
      "cause : 1\n",
      "earn : 1\n",
      "at : 3\n",
      "less : 3\n",
      "But : 1\n",
      "now : 1\n",
      "suppose : 1\n",
      "also : 3\n",
      "fake : 3\n",
      "which : 2\n",
      "consists : 1\n",
      "sockpuppet : 2\n",
      "accounts : 2\n",
      "same : 3\n",
      "wealthy : 1\n",
      "attacker : 3\n",
      "This : 1\n",
      "takes : 1\n",
      "all : 1\n",
      "actions : 1\n",
      "real : 2\n",
      "except : 1\n",
      "instead : 1\n",
      "they : 1\n",
      "support : 1\n",
      "another : 1\n",
      "account : 1\n",
      "If : 1\n",
      "it : 3\n",
      "was : 1\n",
      "possible : 2\n",
      "“ : 1\n",
      "” : 1\n",
      "give : 2\n",
      "personal : 1\n",
      "’ : 2\n",
      "s : 2\n",
      "themselves : 1\n",
      "over : 3\n",
      "again : 1\n",
      "thereby : 1\n",
      "drain : 1\n",
      "funding : 2\n",
      "Any : 1\n",
      "help : 2\n",
      "genuinely : 1\n",
      "under : 1\n",
      "- : 2\n",
      "coordinated : 2\n",
      "parties : 2\n",
      "coordinate : 2\n",
      "will : 1\n",
      "without : 1\n",
      "right : 1\n",
      "safeguards : 1\n",
      "already : 1\n",
      "such : 1\n",
      "many : 1\n",
      "controlled : 1\n",
      "person : 2\n",
      "extracting : 1\n",
      "money : 1\n",
      "from : 1\n",
      "A : 1\n",
      "similar : 1\n",
      "challenge : 1\n",
      "arises : 1\n",
      "when : 1\n",
      "goal : 1\n",
      "not : 1\n",
      "but : 2\n",
      "rather : 1\n",
      "determining : 1\n",
      "what : 1\n",
      "content : 2\n",
      "should : 1\n",
      "most : 1\n",
      "visible : 1\n",
      "What : 1\n",
      "do : 1\n",
      "you : 1\n",
      "think : 1\n",
      "get : 1\n",
      "more : 1\n",
      "dollar : 1\n",
      ": : 1\n",
      "legitimately : 1\n",
      "high : 1\n",
      "quality : 1\n",
      "article : 1\n",
      "benefiting : 2\n",
      "thousands : 1\n",
      "individual : 1\n",
      "relatively : 1\n",
      "slightly : 1\n",
      "or : 1\n",
      "? : 1\n",
      "\n",
      "Grams\n",
      "('The',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('argument',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('is',) : {'count': 6, 'probability': 0.015584415584415584}\n",
      "('as',) : {'count': 4, 'probability': 0.01038961038961039}\n",
      "('follows',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('.',) : {'count': 11, 'probability': 0.02857142857142857}\n",
      "('Suppose',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('that',) : {'count': 6, 'probability': 0.015584415584415584}\n",
      "('there',) : {'count': 4, 'probability': 0.01038961038961039}\n",
      "('some',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('author',) : {'count': 8, 'probability': 0.02077922077922078}\n",
      "('producing',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('a',) : {'count': 13, 'probability': 0.033766233766233764}\n",
      "('public',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('good',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('(',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('eg',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('series',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('of',) : {'count': 18, 'probability': 0.046753246753246755}\n",
      "('blog',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('posts',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "(')',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('provides',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('value',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('to',) : {'count': 7, 'probability': 0.01818181818181818}\n",
      "('each',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('member',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('community',) : {'count': 8, 'probability': 0.02077922077922078}\n",
      "('10000',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('people',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('exists',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('mechanism',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('where',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('members',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('the',) : {'count': 29, 'probability': 0.07532467532467532}\n",
      "('can',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('take',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('an',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('action',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('causes',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('receive',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('gain',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('$',) : {'count': 8, 'probability': 0.02077922077922078}\n",
      "('1',) : {'count': 8, 'probability': 0.02077922077922078}\n",
      "('Unless',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('are',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('extremely',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('altruistic',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "(',',) : {'count': 14, 'probability': 0.03636363636363636}\n",
      "('for',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('work',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('cost',) : {'count': 5, 'probability': 0.012987012987012988}\n",
      "('taking',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('this',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('must',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('be',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('much',) : {'count': 5, 'probability': 0.012987012987012988}\n",
      "('lower',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('than',) : {'count': 5, 'probability': 0.012987012987012988}\n",
      "('otherwise',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('portion',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('benefit',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('captured',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('by',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('supporting',) : {'count': 4, 'probability': 0.01038961038961039}\n",
      "('would',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('smaller',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('and',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('so',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('system',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('collapses',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('into',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('tragedy',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('commons',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('no',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('one',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('supports',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('Hence',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('exist',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('way',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('cause',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('earn',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('at',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('less',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('But',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('now',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('suppose',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('also',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('fake',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('which',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('consists',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('sockpuppet',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('accounts',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('same',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('wealthy',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('attacker',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('This',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('takes',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('all',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('actions',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('real',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('except',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('instead',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('they',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('support',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('another',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('account',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('If',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('it',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('was',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('possible',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('“',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('”',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('give',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('personal',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('’',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('s',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('themselves',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('over',) : {'count': 3, 'probability': 0.007792207792207792}\n",
      "('again',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('thereby',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('drain',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('funding',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('Any',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('help',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('genuinely',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('under',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('-',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('coordinated',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('parties',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('coordinate',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('will',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('without',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('right',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('safeguards',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('already',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('such',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('many',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('controlled',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('person',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('extracting',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('money',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('from',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('A',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('similar',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('challenge',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('arises',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('when',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('goal',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('not',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('but',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('rather',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('determining',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('what',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('content',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('should',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('most',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('visible',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('What',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('do',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('you',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('think',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('get',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('more',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('dollar',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "(':',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('legitimately',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('high',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('quality',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('article',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('benefiting',) : {'count': 2, 'probability': 0.005194805194805195}\n",
      "('thousands',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('individual',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('relatively',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('slightly',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('or',) : {'count': 1, 'probability': 0.0025974025974025974}\n",
      "('?',) : {'count': 1, 'probability': 0.0025974025974025974}\n"
     ]
    }
   ],
   "source": [
    "text_A = tokenizer(text_A)\n",
    "text_B = tokenizer(text_B)\n",
    "\n",
    "model_A = grams(text_A, 1)\n",
    "model_B = grams(text_B, 1)\n",
    "\n",
    "printer(text_A, model_A)\n",
    "print('\\n')\n",
    "printer(text_B, model_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.3  Comparar estadísticas de los dos \"corpus\". ¿Cuáles son las diferencias entre los unigramas más comunes de los dos conjuntos?\n",
    " \n",
    "Se toman los n elementos más comunes para cada corpus. Se extrae del modelo el Token, el Contador, y su Probabilidad. Se puede notar que las palabras comunes con más frecuencia son: `the`, `of`, `a`, `to`, `,`, `.`, que resultan ser artículos y preposiciones, al igual que signos de puntuación. Se puede inferir que los tokens más comunes son de esta categoría, puesto que enlazan otros tokens con un significado de la idea a expresar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (Token, Count, Prob)\t<->\t (Token, Count, Prob)\n",
      "-------------------------------------------------------------\n",
      "1 \t ('the', 11, 0.0474) \t<->\t ('the', 29, 0.0753)\n",
      "2 \t ('of', 10, 0.0431) \t<->\t ('of', 18, 0.0468)\n",
      "3 \t ('a', 10, 0.0431) \t<->\t (',', 14, 0.0364)\n",
      "4 \t (',', 8, 0.0345) \t<->\t ('a', 13, 0.0338)\n",
      "5 \t ('to', 7, 0.0302) \t<->\t ('.', 11, 0.0286)\n",
      "6 \t ('’', 6, 0.0259) \t<->\t ('community', 8, 0.0208)\n",
      "7 \t ('.', 6, 0.0259) \t<->\t ('author', 8, 0.0208)\n",
      "8 \t ('we', 4, 0.0172) \t<->\t ('1', 8, 0.0208)\n",
      "9 \t ('that', 4, 0.0172) \t<->\t ('$', 8, 0.0208)\n",
      "10 \t ('is', 4, 0.0172) \t<->\t ('to', 7, 0.0182)\n"
     ]
    }
   ],
   "source": [
    "sorted_A = sorted(model_A['tokens'].items(), key = lambda kv: (kv[1], kv[0]))\n",
    "sorted_B = sorted(model_B['tokens'].items(), key = lambda kv: (kv[1], kv[0]))\n",
    "\n",
    "items = 10\n",
    "A = list(map(lambda x: list(x), sorted_A[-items:][::-1]))\n",
    "B = list(map(lambda x: list(x), sorted_B[-items:][::-1]))\n",
    "\n",
    "for idx, item in enumerate(A):\n",
    "    A[idx].append(round(model_A['grams'][tuple([item[0]])]['probability'], 4))\n",
    "\n",
    "for idx, item in enumerate(B):\n",
    "    B[idx].append(round(model_B['grams'][tuple([item[0]])]['probability'], 4))\n",
    "\n",
    "print('\\t (Token, Count, Prob)\\t<->\\t (Token, Count, Prob)')\n",
    "print('-------------------------------------------------------------')\n",
    "for idx, item in enumerate(list(zip(A, B))):\n",
    "    print(idx + 1, '\\t', tuple(item[0]), '\\t<->\\t', tuple(item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Adicionar una opción que genere frases aleatoriamente (como el algoritmo visto en clase usando N= 1, 2, 3 y 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_generator(corpus):\n",
    "    phrase = [x for x in corpus]\n",
    "    phrase = list(flatten(random.sample(phrase, random.randint(20, 60))))\n",
    "    return \" \".join(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. `N = 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free game purchase being identities only identity trying practice representing type tradeoff not functionality decision incentivize s impossible general with than building prediction but of determine explicitly public the really safe viable legitimate explicit where is One noisy small In maximize market . subsidizing number between this\n"
     ]
    }
   ],
   "source": [
    "model_A_N_1 = grams(text_A, 1)\n",
    "print(phrase_generator(model_A_N_1['grams']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. `N = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- safe t matter via its be identity one tries solving governance its impact is limited However , identifying public unfortunately cannot identity - re just replace the anything but more explicit in practice purchase advertising incentivize legitimate the property just scaling And often on the , good where we could try the more . One preserve the maximum value s take maximize is the right free , general case take a indicator to subsidizing plutocracy a more that we between either in the collusion - property of impossible tradeoff\n"
     ]
    }
   ],
   "source": [
    "model_A_N_2 = grams(text_A, 2)\n",
    "print(phrase_generator(model_A_N_2['grams']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. `N = 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ s take ’ t matter free , building is already assumed things that mechanisms determine the value that is already market on the to make this mechanisms for identifying to purchase advertising a system where the more general could try to that we ’ assumed to be of this type safe . If of a game prediction market on governance decision via re just scaling space , but at why , can do is One could try not really solving something other than ’ re not decision via its of a coin only coins do the case of t matter and practice prices are don ’ t public goods or for anything but this viable for - free , And often the between either failing very small number a token representing noisy an indicator t easily determine\n"
     ]
    }
   ],
   "source": [
    "model_A_N_3 = grams(text_A, 3)\n",
    "print(phrase_generator(model_A_N_3['grams']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. `N = 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solving governance , we panel with a prediction a token , good of the content curation maximize is explicitly something purchase advertising space , can do is limited coins do , there not really solving governance do , there is ’ re trying to of a governance decision the right to purchase that is already assumed something other than maximum already assumed to be or over - subsidizing governance , we ’ either failing to incentivize gadget that is already very large decisions . the content curation example trusted . One could case where we can above , we ’ bads unfortunately cannot be to incentivize legitimate public but a very small take a more explicit incentivize legitimate public goods free or collusion - , but in practice why , in the practice prices are too functionality of a governance building a system where ’ s take a explicitly something other than determine the value of the value that we ’ re not really the case of the an indicator to make re just scaling the unfortunately cannot be identity governance gadget that is other than maximum value mechanisms of this type things that mechanisms of there is an impossible identity - free , , building a system maximum value of a ’ re just scaling , good mechanisms for of a governance gadget One could try to\n"
     ]
    }
   ],
   "source": [
    "model_A_N_4 = grams(text_A, 4)\n",
    "print(phrase_generator(model_A_N_4['grams']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Adicionar una opción para computar la \"perplexity\" en un conjunto de pueba \"testing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP(W) = 0\n"
     ]
    }
   ],
   "source": [
    "def perplexity(model, corpus):\n",
    "    n = len(next(iter(model['grams'])))\n",
    "    corpus_model = grams(corpus, n)\n",
    "    p = next(iter(corpus_model['grams']))\n",
    "    try:\n",
    "        p = model['tokens'][p[0]] / sum([model['tokens'][x] for x in model['tokens']])\n",
    "    except KeyError:\n",
    "        p = 0\n",
    "    for gram in corpus_model['grams']:\n",
    "        try:\n",
    "            p *= model['grams'][gram]['probability']\n",
    "        except KeyError:\n",
    "            p = 0\n",
    "            break\n",
    "            \n",
    "    pp = pow(1 / p, 1 / n) if p != 0 else 0\n",
    "    print(f\"PP(W) = {pp}\")\n",
    "    \n",
    "test_text = '''I don't deny it, I was a Windows user before, and of course, how couldn't I be one? Here, when you bought a new computer, they sold it with a pirate copy of Windows 98 Plus SE. It was by the middle of 2000 when a friend gave me a copy of Knoppix 1.4. I was so excited with that. I went from frustration to love in that copy, each time I screwed something I learned something new and a whole new universe of possibilities was opened before me.\n",
    "\n",
    "And yes, since then I started to use Linux. I used before distros such as SuSe, Mandriva, Slacware until I met Debian (and its derivatives) and I remained there. Since 2 years ago I've been using Ubuntu, the official image that comes with Gnome, and that's just because I don't like Unity.\n",
    "\n",
    "Well, but why Linux? The code is free (as in freedom), and it allows me to do whatever I want. There is a huge community that leads to share the knowledge, without expending too much money (developers need money too) on learning something that belongs to the public domain; you can download a legal copy, redistribute it, copy it (nonprofit) and it doesn't cost. I'm not saying with this that I don't support the project, because I do, but actually every post or comment I do about Linux is actually a way of contributing to it.'''\n",
    "\n",
    "\n",
    "test_text = tokenizer(test_text)\n",
    "\n",
    "perplexity(model_A_N_2, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la función anterior podemos decir que al no tener implementado el suavizado es muy sensible y la mayor cantidad de veces va a fallar, por lo que su resultado es 0 frecuentemente. Si se usa un set de pruebas basado en el modelo, funciona.\n",
    "\n",
    "Como a continuación, del ejemplo de las diapositivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP(W) = 4.898979485566356\n"
     ]
    }
   ],
   "source": [
    "# Textos en minusculas para evitar problemas\n",
    "\n",
    "model_text = '''esta es la tienda\n",
    "\n",
    "este estaba en la casa que jack construyo'''\n",
    "\n",
    "test_text = '''esta es la casa'''\n",
    "\n",
    "model_text = tokenizer(model_text)\n",
    "test_text = tokenizer(test_text)\n",
    "\n",
    "model = grams(model_text, 2)\n",
    "\n",
    "perplexity(model, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extender el programa para usar \"Suavizado\" Laplaciano (adicionar 1) como opción. Esta opción debe retornar un diccionario en la misma forma del punto 1. Probar y comparar con el mismo corpus del punto 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "['D', 'E', 'C', 'D', 'E']\n",
      "['A', 'C', 'D', 'D']\n",
      "\n",
      "Tokens count:\n",
      "A : 2\n",
      "B : 1\n",
      "C : 3\n",
      "D : 5\n",
      "E : 3\n",
      "\n",
      "Grams\n",
      "('A', 'B') : {'count': 1, 'probability': 0.5}\n",
      "('B', 'C') : {'count': 1, 'probability': 1.0}\n",
      "('C', 'D') : {'count': 3, 'probability': 1.0}\n",
      "('D', 'E') : {'count': 3, 'probability': 0.6}\n",
      "('E', 'C') : {'count': 1, 'probability': 0.3333333333333333}\n",
      "('A', 'C') : {'count': 1, 'probability': 0.5}\n",
      "('D', 'D') : {'count': 1, 'probability': 0.2}\n",
      "Smoothing token counting\n",
      "------------------------\n",
      "   A  B  C  D  E\n",
      "A  1  2  2  1  1\n",
      "B  1  1  2  1  1\n",
      "C  1  1  1  4  1\n",
      "D  1  1  1  2  4\n",
      "E  1  1  2  1  1\n",
      "\n",
      "Laplace Smoothing probabilities\n",
      "-------------------------------\n",
      "          A         B         C         D         E\n",
      "A  0.052632  0.105263  0.105263  0.052632  0.052632\n",
      "B  0.052632  0.052632  0.105263  0.052632  0.052632\n",
      "C  0.052632  0.052632  0.052632  0.210526  0.052632\n",
      "D  0.052632  0.052632  0.052632  0.105263  0.210526\n",
      "E  0.052632  0.052632  0.105263  0.052632  0.052632\n"
     ]
    }
   ],
   "source": [
    "def laplace_smoother(corpus):\n",
    "    model = grams(corpus, 2)\n",
    "    count = {y: {x: 1 for x in model['tokens']} for y in model['tokens']}\n",
    "    keys = [x for x in model['tokens']]\n",
    "    for gram in model['grams']:\n",
    "        count[gram[1]][gram[0]] += model['grams'][gram]['count']\n",
    "    res = pandas.DataFrame(data=count, columns=keys)\n",
    "    print('Smoothing token counting')\n",
    "    print('------------------------')\n",
    "    print(res)\n",
    "    \n",
    "    nv = len(keys) + sum([model['tokens'][val] for val in model['tokens']])\n",
    "    prob = count\n",
    "    for x in prob:\n",
    "        for y in prob[x]:\n",
    "            prob[y][x] /= nv\n",
    "    res = pandas.DataFrame(data=prob, columns=keys)\n",
    "    print('\\nLaplace Smoothing probabilities')\n",
    "    print('-------------------------------')\n",
    "    print(res)\n",
    "\n",
    "corpus = [\n",
    "    ['A', 'B', 'C', 'D', 'E'],\n",
    "    ['D', 'E', 'C', 'D', 'E'],\n",
    "    ['A', 'C', 'D', 'D']\n",
    "]\n",
    "\n",
    "printer(corpus, grams(corpus, 2))\n",
    "laplace_smoother(corpus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
