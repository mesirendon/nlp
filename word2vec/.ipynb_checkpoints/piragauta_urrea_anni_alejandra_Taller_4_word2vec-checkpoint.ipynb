{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158314, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons_dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    17814\n",
       "spoken_words          26459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    0\n",
       "spoken_words          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)\n",
    "    \n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 1.53 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85960, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:46:31: 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:47:10: collecting all words and their counts\n",
      "INFO - 18:47:10: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #10000, processed 63561 words and 52716 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #20000, processed 130949 words and 99637 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #30000, processed 192972 words and 138212 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #40000, processed 249845 words and 172230 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #50000, processed 311277 words and 208051 word types\n",
      "INFO - 18:47:10: PROGRESS: at sentence #60000, processed 373597 words and 243068 word types\n",
      "INFO - 18:47:11: PROGRESS: at sentence #70000, processed 436446 words and 278001 word types\n",
      "INFO - 18:47:11: PROGRESS: at sentence #80000, processed 497916 words and 311099 word types\n",
      "INFO - 18:47:11: collected 329869 word types from a corpus of 537147 words (unigram + bigrams) and 85960 sentences\n",
      "INFO - 18:47:11: using 329869 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:49:32: source_vocab length 329869\n",
      "INFO - 18:49:37: Phraser built with 126 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29643"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'like', 'know', 'get', 'hey', 'think', 'right', 'look', 'want', 'come']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cores:  8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "print('cores: ', cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the vocabulary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:51:40: collecting all words and their counts\n",
      "INFO - 18:51:40: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 18:51:40: PROGRESS: at sentence #10000, processed 61706 words, keeping 9491 word types\n",
      "INFO - 18:51:40: PROGRESS: at sentence #20000, processed 127342 words, keeping 14373 word types\n",
      "INFO - 18:51:40: PROGRESS: at sentence #30000, processed 187807 words, keeping 17431 word types\n",
      "INFO - 18:51:41: PROGRESS: at sentence #40000, processed 243316 words, keeping 20124 word types\n",
      "INFO - 18:51:41: PROGRESS: at sentence #50000, processed 303167 words, keeping 22558 word types\n",
      "INFO - 18:51:41: PROGRESS: at sentence #60000, processed 363915 words, keeping 24804 word types\n",
      "INFO - 18:51:42: PROGRESS: at sentence #70000, processed 425375 words, keeping 26960 word types\n",
      "INFO - 18:51:42: PROGRESS: at sentence #80000, processed 485514 words, keeping 28777 word types\n",
      "INFO - 18:51:42: collected 29643 word types from a corpus of 523645 raw words and 85960 sentences\n",
      "INFO - 18:51:42: Loading a fresh vocabulary\n",
      "INFO - 18:51:42: effective_min_count=20 retains 3315 unique words (11% of original 29643, drops 26328)\n",
      "INFO - 18:51:42: effective_min_count=20 leaves 437848 word corpus (83% of original 523645, drops 85797)\n",
      "INFO - 18:51:42: deleting the raw counts dictionary of 29643 items\n",
      "INFO - 18:51:42: sample=6e-05 downsamples 1204 most-common words\n",
      "INFO - 18:51:42: downsampling leaves estimated 199419 word corpus (45.5% of prior 437848)\n",
      "INFO - 18:51:42: estimated required memory for 3315 words and 300 dimensions: 9613500 bytes\n",
      "INFO - 18:51:42: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.05 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:52:42: training model with 7 workers on 3315 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 18:52:43: EPOCH 1 - PROGRESS: at 33.38% examples, 67139 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:44: EPOCH 1 - PROGRESS: at 65.22% examples, 62331 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:45: EPOCH 1 - PROGRESS: at 98.13% examples, 63150 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:45: EPOCH - 1 : training on 523645 raw words (199755 effective words) took 3.1s, 64163 effective words/s\n",
      "INFO - 18:52:46: EPOCH 2 - PROGRESS: at 33.38% examples, 64687 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:47: EPOCH 2 - PROGRESS: at 69.06% examples, 64879 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:48: EPOCH 2 - PROGRESS: at 97.46% examples, 62363 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:48: EPOCH - 2 : training on 523645 raw words (198855 effective words) took 3.2s, 61921 effective words/s\n",
      "INFO - 18:52:49: EPOCH 3 - PROGRESS: at 31.39% examples, 61397 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:52:50: EPOCH 3 - PROGRESS: at 65.22% examples, 62178 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:51: EPOCH 3 - PROGRESS: at 95.70% examples, 61637 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:52: EPOCH - 3 : training on 523645 raw words (199333 effective words) took 3.2s, 62051 effective words/s\n",
      "INFO - 18:52:53: EPOCH 4 - PROGRESS: at 31.39% examples, 63920 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:52:54: EPOCH 4 - PROGRESS: at 69.06% examples, 67870 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:55: EPOCH - 4 : training on 523645 raw words (199442 effective words) took 3.0s, 67084 effective words/s\n",
      "INFO - 18:52:56: EPOCH 5 - PROGRESS: at 35.35% examples, 69598 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:57: EPOCH 5 - PROGRESS: at 70.97% examples, 68718 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:52:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:52:58: EPOCH - 5 : training on 523645 raw words (199772 effective words) took 3.0s, 67094 effective words/s\n",
      "INFO - 18:52:59: EPOCH 6 - PROGRESS: at 37.41% examples, 71859 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:00: EPOCH 6 - PROGRESS: at 72.85% examples, 69377 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:00: EPOCH - 6 : training on 523645 raw words (199674 effective words) took 2.8s, 70881 effective words/s\n",
      "INFO - 18:53:01: EPOCH 7 - PROGRESS: at 35.35% examples, 70542 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:02: EPOCH 7 - PROGRESS: at 72.85% examples, 71468 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:03: EPOCH - 7 : training on 523645 raw words (199235 effective words) took 2.8s, 70334 effective words/s\n",
      "INFO - 18:53:04: EPOCH 8 - PROGRESS: at 35.35% examples, 70570 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:05: EPOCH 8 - PROGRESS: at 72.85% examples, 71339 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:06: EPOCH - 8 : training on 523645 raw words (199529 effective words) took 2.7s, 72806 effective words/s\n",
      "INFO - 18:53:07: EPOCH 9 - PROGRESS: at 31.39% examples, 63995 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:08: EPOCH 9 - PROGRESS: at 67.19% examples, 66109 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:09: EPOCH - 9 : training on 523645 raw words (198889 effective words) took 2.9s, 67547 effective words/s\n",
      "INFO - 18:53:10: EPOCH 10 - PROGRESS: at 27.49% examples, 54750 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:11: EPOCH 10 - PROGRESS: at 55.69% examples, 53222 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:12: EPOCH 10 - PROGRESS: at 86.15% examples, 55730 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:53:12: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:12: EPOCH - 10 : training on 523645 raw words (199127 effective words) took 3.5s, 56683 effective words/s\n",
      "INFO - 18:53:14: EPOCH 11 - PROGRESS: at 29.43% examples, 57561 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:15: EPOCH 11 - PROGRESS: at 59.45% examples, 57035 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:16: EPOCH 11 - PROGRESS: at 84.22% examples, 54267 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:16: EPOCH - 11 : training on 523645 raw words (199146 effective words) took 3.6s, 55459 effective words/s\n",
      "INFO - 18:53:17: EPOCH 12 - PROGRESS: at 29.43% examples, 59878 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:18: EPOCH 12 - PROGRESS: at 63.31% examples, 60414 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:19: EPOCH 12 - PROGRESS: at 95.70% examples, 60453 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:19: EPOCH - 12 : training on 523645 raw words (199233 effective words) took 3.2s, 61462 effective words/s\n",
      "INFO - 18:53:20: EPOCH 13 - PROGRESS: at 27.49% examples, 53637 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:53:21: EPOCH 13 - PROGRESS: at 61.41% examples, 57198 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:22: EPOCH 13 - PROGRESS: at 95.70% examples, 60514 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:23: EPOCH - 13 : training on 523645 raw words (199783 effective words) took 3.3s, 61050 effective words/s\n",
      "INFO - 18:53:24: EPOCH 14 - PROGRESS: at 31.39% examples, 61153 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:25: EPOCH 14 - PROGRESS: at 63.31% examples, 60541 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:26: EPOCH - 14 : training on 523645 raw words (199586 effective words) took 3.1s, 64879 effective words/s\n",
      "INFO - 18:53:27: EPOCH 15 - PROGRESS: at 29.43% examples, 59721 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:28: EPOCH 15 - PROGRESS: at 61.41% examples, 58849 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:29: EPOCH 15 - PROGRESS: at 91.99% examples, 59310 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:29: EPOCH - 15 : training on 523645 raw words (199069 effective words) took 3.3s, 59723 effective words/s\n",
      "INFO - 18:53:30: EPOCH 16 - PROGRESS: at 29.43% examples, 58039 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:31: EPOCH 16 - PROGRESS: at 67.19% examples, 64278 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:32: EPOCH - 16 : training on 523645 raw words (199228 effective words) took 3.0s, 65644 effective words/s\n",
      "INFO - 18:53:33: EPOCH 17 - PROGRESS: at 35.35% examples, 70547 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:34: EPOCH 17 - PROGRESS: at 72.85% examples, 69663 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:35: EPOCH - 17 : training on 523645 raw words (199507 effective words) took 2.9s, 69906 effective words/s\n",
      "INFO - 18:53:36: EPOCH 18 - PROGRESS: at 31.39% examples, 63697 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:37: EPOCH 18 - PROGRESS: at 69.06% examples, 68225 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:38: EPOCH - 18 : training on 523645 raw words (199602 effective words) took 2.9s, 69013 effective words/s\n",
      "INFO - 18:53:39: EPOCH 19 - PROGRESS: at 35.35% examples, 69239 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:40: EPOCH 19 - PROGRESS: at 70.97% examples, 67531 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:53:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:41: EPOCH - 19 : training on 523645 raw words (199656 effective words) took 2.9s, 68992 effective words/s\n",
      "INFO - 18:53:42: EPOCH 20 - PROGRESS: at 33.38% examples, 67309 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:43: EPOCH 20 - PROGRESS: at 70.97% examples, 65322 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:44: EPOCH - 20 : training on 523645 raw words (199528 effective words) took 3.0s, 67187 effective words/s\n",
      "INFO - 18:53:45: EPOCH 21 - PROGRESS: at 35.35% examples, 69406 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:46: EPOCH 21 - PROGRESS: at 74.73% examples, 71202 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:47: EPOCH - 21 : training on 523645 raw words (199284 effective words) took 2.9s, 69660 effective words/s\n",
      "INFO - 18:53:48: EPOCH 22 - PROGRESS: at 33.38% examples, 66788 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:49: EPOCH 22 - PROGRESS: at 70.97% examples, 68510 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:49: EPOCH - 22 : training on 523645 raw words (198940 effective words) took 2.9s, 69135 effective words/s\n",
      "INFO - 18:53:51: EPOCH 23 - PROGRESS: at 33.38% examples, 65191 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:52: EPOCH 23 - PROGRESS: at 70.97% examples, 67156 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:52: EPOCH - 23 : training on 523645 raw words (199452 effective words) took 2.9s, 68686 effective words/s\n",
      "INFO - 18:53:53: EPOCH 24 - PROGRESS: at 33.38% examples, 66084 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:54: EPOCH 24 - PROGRESS: at 67.19% examples, 65241 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:55: EPOCH 24 - PROGRESS: at 99.34% examples, 64850 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:55: EPOCH - 24 : training on 523645 raw words (199363 effective words) took 3.1s, 65230 effective words/s\n",
      "INFO - 18:53:57: EPOCH 25 - PROGRESS: at 31.39% examples, 62098 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:58: EPOCH 25 - PROGRESS: at 65.22% examples, 62562 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:59: EPOCH 25 - PROGRESS: at 97.46% examples, 62395 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:53:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:53:59: EPOCH - 25 : training on 523645 raw words (199378 effective words) took 3.2s, 62513 effective words/s\n",
      "INFO - 18:54:00: EPOCH 26 - PROGRESS: at 33.38% examples, 65706 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:01: EPOCH 26 - PROGRESS: at 67.19% examples, 64401 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:02: EPOCH - 26 : training on 523645 raw words (199376 effective words) took 3.0s, 66768 effective words/s\n",
      "INFO - 18:54:03: EPOCH 27 - PROGRESS: at 31.39% examples, 63879 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:04: EPOCH 27 - PROGRESS: at 69.06% examples, 66623 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:05: EPOCH - 27 : training on 523645 raw words (199427 effective words) took 2.9s, 69184 effective words/s\n",
      "INFO - 18:54:06: EPOCH 28 - PROGRESS: at 31.39% examples, 62701 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:07: EPOCH 28 - PROGRESS: at 69.06% examples, 66900 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:07: EPOCH - 28 : training on 523645 raw words (199613 effective words) took 2.9s, 69167 effective words/s\n",
      "INFO - 18:54:09: EPOCH 29 - PROGRESS: at 35.35% examples, 68402 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:10: EPOCH 29 - PROGRESS: at 69.06% examples, 66310 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:54:10: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:10: EPOCH - 29 : training on 523645 raw words (199377 effective words) took 2.9s, 68580 effective words/s\n",
      "INFO - 18:54:11: EPOCH 30 - PROGRESS: at 35.35% examples, 69296 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:12: EPOCH 30 - PROGRESS: at 70.97% examples, 68248 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 18:54:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 18:54:13: EPOCH - 30 : training on 523645 raw words (199395 effective words) took 3.0s, 65965 effective words/s\n",
      "INFO - 18:54:13: training on a 15709350 raw words (5981554 effective words) took 91.4s, 65453 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.52 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:56:07: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depressed', 0.8020632863044739),\n",
       " ('marge', 0.7842615246772766),\n",
       " ('snuggle', 0.770393967628479),\n",
       " ('sweetheart', 0.7703680992126465),\n",
       " ('terrific', 0.7653756141662598),\n",
       " ('crummy', 0.7538477182388306),\n",
       " ('feel_well', 0.7537402510643005),\n",
       " ('creepy', 0.7515972256660461),\n",
       " ('good_friend', 0.7505632042884827),\n",
       " ('nervous', 0.7461447715759277)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most similar to Homero\n",
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('select', 0.790610671043396),\n",
       " ('council', 0.7715891599655151),\n",
       " ('congratulation', 0.7705077528953552),\n",
       " ('robert', 0.7687914967536926),\n",
       " ('aboard', 0.7673720121383667),\n",
       " ('pleased', 0.7658112049102783),\n",
       " ('united_state', 0.7519148588180542),\n",
       " ('recent', 0.7456115484237671),\n",
       " ('threat', 0.7453498840332031),\n",
       " ('elect', 0.7438726425170898)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('homer', 0.7842615246772766),\n",
       " ('sorry', 0.7802915573120117),\n",
       " ('nervous', 0.7766187191009521),\n",
       " ('depressed', 0.7650347948074341),\n",
       " ('snuggle', 0.7640378475189209),\n",
       " ('surprised', 0.7563819289207458),\n",
       " ('rude', 0.7559762597084045),\n",
       " ('sweetheart', 0.7519235014915466),\n",
       " ('feel_well', 0.7512655258178711),\n",
       " ('hopeless', 0.7505140900611877)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"marge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lisa', 0.8627593517303467),\n",
       " ('hearing', 0.8017841577529907),\n",
       " ('strangle', 0.7903481721878052),\n",
       " ('substitute', 0.7894383668899536),\n",
       " ('convince', 0.7877330780029297),\n",
       " ('badly', 0.7814056277275085),\n",
       " ('jealous', 0.7771100401878357),\n",
       " ('mom', 0.7760716080665588),\n",
       " ('muntz', 0.7737230658531189),\n",
       " ('mom_dad', 0.7711635828018188)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('groundskeeper', 0.9361370205879211),\n",
       " ('aye', 0.603545606136322),\n",
       " ('puke', 0.6017469763755798),\n",
       " (\"'_tis\", 0.5868011713027954),\n",
       " ('seymour', 0.5557730197906494),\n",
       " ('mess', 0.5498030185699463),\n",
       " ('oi', 0.548999011516571),\n",
       " ('arrr', 0.542657732963562),\n",
       " ('grass', 0.5248633027076721),\n",
       " ('field', 0.5233394503593445)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"willie\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90058094"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"moe\", 'tavern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199063"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('maggie', 'baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686138"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('bart', 'nelson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odd-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jimbo'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'nelson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nelson'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'homer'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['homer', 'patty', 'selma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('see', 0.6590675115585327),\n",
       " ('admire', 0.6295326352119446),\n",
       " ('care', 0.6255589723587036)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lisa', 0.7746933698654175),\n",
       " ('parent', 0.6939990520477295),\n",
       " ('surprised', 0.6744728088378906)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
